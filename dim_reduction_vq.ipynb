{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/tagsearch/lib/python3.11/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tagmatch.vec_db import Embedder\n",
    "import numpy as np\n",
    "from tagmatch.vec_db import VecDB\n",
    "import itertools\n",
    "import pickle\n",
    "from create_dummy_tags import tags\n",
    "import nanopq\n",
    "from pydantic_settings import BaseSettings\n",
    "class Settings(BaseSettings):\n",
    "    model_name: str\n",
    "    cache_dir: str\n",
    "    qdrant_host: str\n",
    "    qdrant_port: int\n",
    "    qdrant_collection: str\n",
    "    reduced_embed_dim: int\n",
    "\n",
    "    class Config:\n",
    "        env_file = \".env\"\n",
    "settings=Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"additional_tags.txt\") as f:\n",
    "    additional_tags = f.readlines()\n",
    "    additional_tags = [t.split(\",\") for t in additional_tags]\n",
    "    additional_tags = list(itertools.chain.from_iterable(additional_tags))\n",
    "    additional_tags = [t.lstrip().replace(r'\\n','') for t in additional_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_tags = tags + additional_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 55043.36it/s]\n"
     ]
    }
   ],
   "source": [
    "embedder = Embedder(model_name=settings.model_name,cache_dir=settings.cache_dir)\n",
    "tag_embeddings = [embedder.embed(tag) for tag in extended_tags]\n",
    "embed_vecs=np.asarray(tag_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 64, Ks: 256, metric : <class 'numpy.uint8'>, code_dtype: l2\n",
      "iter: 20, seed: 123\n",
      "Training the subspace: 0 / 64\n",
      "Training the subspace: 1 / 64\n",
      "Training the subspace: 2 / 64\n",
      "Training the subspace: 3 / 64\n",
      "Training the subspace: 4 / 64\n",
      "Training the subspace: 5 / 64\n",
      "Training the subspace: 6 / 64\n",
      "Training the subspace: 7 / 64\n",
      "Training the subspace: 8 / 64\n",
      "Training the subspace: 9 / 64\n",
      "Training the subspace: 10 / 64\n",
      "Training the subspace: 11 / 64\n",
      "Training the subspace: 12 / 64\n",
      "Training the subspace: 13 / 64\n",
      "Training the subspace: 14 / 64\n",
      "Training the subspace: 15 / 64\n",
      "Training the subspace: 16 / 64\n",
      "Training the subspace: 17 / 64\n",
      "Training the subspace: 18 / 64\n",
      "Training the subspace: 19 / 64\n",
      "Training the subspace: 20 / 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/tagsearch/lib/python3.11/site-packages/nanopq/pq.py:123: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  self.codewords[m], _ = kmeans2(vecs_sub, self.Ks, iter=iter, minit=minit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the subspace: 21 / 64\n",
      "Training the subspace: 22 / 64\n",
      "Training the subspace: 23 / 64\n",
      "Training the subspace: 24 / 64\n",
      "Training the subspace: 25 / 64\n",
      "Training the subspace: 26 / 64\n",
      "Training the subspace: 27 / 64\n",
      "Training the subspace: 28 / 64\n",
      "Training the subspace: 29 / 64\n",
      "Training the subspace: 30 / 64\n",
      "Training the subspace: 31 / 64\n",
      "Training the subspace: 32 / 64\n",
      "Training the subspace: 33 / 64\n",
      "Training the subspace: 34 / 64\n",
      "Training the subspace: 35 / 64\n",
      "Training the subspace: 36 / 64\n",
      "Training the subspace: 37 / 64\n",
      "Training the subspace: 38 / 64\n",
      "Training the subspace: 39 / 64\n",
      "Training the subspace: 40 / 64\n",
      "Training the subspace: 41 / 64\n",
      "Training the subspace: 42 / 64\n",
      "Training the subspace: 43 / 64\n",
      "Training the subspace: 44 / 64\n",
      "Training the subspace: 45 / 64\n",
      "Training the subspace: 46 / 64\n",
      "Training the subspace: 47 / 64\n",
      "Training the subspace: 48 / 64\n",
      "Training the subspace: 49 / 64\n",
      "Training the subspace: 50 / 64\n",
      "Training the subspace: 51 / 64\n",
      "Training the subspace: 52 / 64\n",
      "Training the subspace: 53 / 64\n",
      "Training the subspace: 54 / 64\n",
      "Training the subspace: 55 / 64\n",
      "Training the subspace: 56 / 64\n",
      "Training the subspace: 57 / 64\n",
      "Training the subspace: 58 / 64\n",
      "Training the subspace: 59 / 64\n",
      "Training the subspace: 60 / 64\n",
      "Training the subspace: 61 / 64\n",
      "Training the subspace: 62 / 64\n",
      "Training the subspace: 63 / 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nanopq.pq.PQ at 0x168a0c8d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq = nanopq.PQ(M=64)\n",
    "pq.fit(embed_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding the subspace: 0 / 64\n",
      "Encoding the subspace: 1 / 64\n",
      "Encoding the subspace: 2 / 64\n",
      "Encoding the subspace: 3 / 64\n",
      "Encoding the subspace: 4 / 64\n",
      "Encoding the subspace: 5 / 64\n",
      "Encoding the subspace: 6 / 64\n",
      "Encoding the subspace: 7 / 64\n",
      "Encoding the subspace: 8 / 64\n",
      "Encoding the subspace: 9 / 64\n",
      "Encoding the subspace: 10 / 64\n",
      "Encoding the subspace: 11 / 64\n",
      "Encoding the subspace: 12 / 64\n",
      "Encoding the subspace: 13 / 64\n",
      "Encoding the subspace: 14 / 64\n",
      "Encoding the subspace: 15 / 64\n",
      "Encoding the subspace: 16 / 64\n",
      "Encoding the subspace: 17 / 64\n",
      "Encoding the subspace: 18 / 64\n",
      "Encoding the subspace: 19 / 64\n",
      "Encoding the subspace: 20 / 64\n",
      "Encoding the subspace: 21 / 64\n",
      "Encoding the subspace: 22 / 64\n",
      "Encoding the subspace: 23 / 64\n",
      "Encoding the subspace: 24 / 64\n",
      "Encoding the subspace: 25 / 64\n",
      "Encoding the subspace: 26 / 64\n",
      "Encoding the subspace: 27 / 64\n",
      "Encoding the subspace: 28 / 64\n",
      "Encoding the subspace: 29 / 64\n",
      "Encoding the subspace: 30 / 64\n",
      "Encoding the subspace: 31 / 64\n",
      "Encoding the subspace: 32 / 64\n",
      "Encoding the subspace: 33 / 64\n",
      "Encoding the subspace: 34 / 64\n",
      "Encoding the subspace: 35 / 64\n",
      "Encoding the subspace: 36 / 64\n",
      "Encoding the subspace: 37 / 64\n",
      "Encoding the subspace: 38 / 64\n",
      "Encoding the subspace: 39 / 64\n",
      "Encoding the subspace: 40 / 64\n",
      "Encoding the subspace: 41 / 64\n",
      "Encoding the subspace: 42 / 64\n",
      "Encoding the subspace: 43 / 64\n",
      "Encoding the subspace: 44 / 64\n",
      "Encoding the subspace: 45 / 64\n",
      "Encoding the subspace: 46 / 64\n",
      "Encoding the subspace: 47 / 64\n",
      "Encoding the subspace: 48 / 64\n",
      "Encoding the subspace: 49 / 64\n",
      "Encoding the subspace: 50 / 64\n",
      "Encoding the subspace: 51 / 64\n",
      "Encoding the subspace: 52 / 64\n",
      "Encoding the subspace: 53 / 64\n",
      "Encoding the subspace: 54 / 64\n",
      "Encoding the subspace: 55 / 64\n",
      "Encoding the subspace: 56 / 64\n",
      "Encoding the subspace: 57 / 64\n",
      "Encoding the subspace: 58 / 64\n",
      "Encoding the subspace: 59 / 64\n",
      "Encoding the subspace: 60 / 64\n",
      "Encoding the subspace: 61 / 64\n",
      "Encoding the subspace: 62 / 64\n",
      "Encoding the subspace: 63 / 64\n"
     ]
    }
   ],
   "source": [
    "quantized_embeddings = pq.encode(embed_vecs[:len(tags)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_db = VecDB(\n",
    "    host=\"http://localhost\",\n",
    "    port=6333,\n",
    "    collection=\"pca_train_test_reduced\",\n",
    "    vector_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,vec in zip(tags,quantized_embeddings):\n",
    "    vec_db.store(vec,{\"name\":name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_vector_matches = [vec_db.find_closest(query_vector, 5) for query_vector in quantized_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=12577971619524015535, version=0, score=1.0000001, payload={'name': 'Apollo 11'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=13597808653146884023, version=168, score=0.86957663, payload={'name': 'White Dwarf'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=10869594146043148504, version=126, score=0.86057645, payload={'name': 'Space Policy'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=13339345376839178795, version=72, score=0.83821887, payload={'name': 'Artificial Gravity'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=12404555467008947710, version=165, score=0.8297652, payload={'name': 'Universe'}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_vector_matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_db_full = VecDB(\n",
    "    host=\"http://localhost\",\n",
    "    port=6333,\n",
    "    collection=\"train_test\",\n",
    "    vector_size=embedder.embedding_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,vec in zip(tags,embed_vecs):\n",
    "    vec_db_full.store(vec,{\"name\":name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector_matches = [vec_db_full.find_closest(query_vector, 5) for query_vector in embed_vecs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=10590435730962342384, version=0, score=0.9999999, payload={'name': 'Apollo 11'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=10938686976877578232, version=46, score=0.7471009, payload={'name': 'Moon Mission'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=9329965740516622676, version=1, score=0.72500336, payload={'name': 'Moon'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=12340914482847751841, version=80, score=0.7157799, payload={'name': 'Lunar Base'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=13599961305190117704, version=14, score=0.6981933, payload={'name': 'NASA'}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pca,open(\"pca.pkl\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
